---
layout: post-no-feature
title: Accelerating Inference In Foundational LLMs & Text Generation
description: "This blog post summarizes Trade offs, Output-approximating methods and Output-preserving methods while accelerating inference in LLMs"
categories: articles
tags: [sample post, images, test]
---


### Trade offs

#### The Quality vs Latency/Cost Tradeoff

#### The Latency vs Cost Tradeoff

### Output-approximating methods

#### Quantization

#### Distillation

### Output-preserving methods

#### Flash Attention

#### Prefix Caching

#### Speculative Decoding

### Batching and Parallelization
